{
  "user_idea": "Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction",
  "success": true,
  "iterations": 1,
  "selected_patterns": {
    "stability": [
      "pattern_100",
      "pattern_115",
      "pattern_57",
      "pattern_102",
      "pattern_114"
    ],
    "novelty": [
      "pattern_49",
      "pattern_114",
      "pattern_94",
      "pattern_68",
      "pattern_7"
    ],
    "domain_distance": [
      "pattern_49",
      "pattern_100",
      "pattern_114",
      "pattern_99",
      "pattern_94"
    ]
  },
  "final_story": {
    "title": "Autoregressive Image Diffusion for Efficient Posterior Sampling in Accelerated MRI Reconstruction",
    "abstract": "Accelerated MRI reconstruction requires sampling from complex posterior distributions to recover high-fidelity images from undersampled k-space data. We propose the Autoregressive Image Diffusion (AID) model, a novel framework designed to leverage the strengths of diffusion models for image sequence generation within the context of MRI reconstruction. To address the critical challenge of computational latency, we integrate advanced numerical integration techniques that transform the traditionally slow diffusion sampling process into a highly efficient operation. By utilizing a Diffusion Exponential Integrator Sampler (DEIS), our approach minimizes discretization errors and significantly reduces the number of required function evaluations. This allows AID to perform rapid posterior sampling while maintaining the structural coherence essential for medical imaging. Our results demonstrate that AID achieves superior reconstruction quality and speed compared to existing methods, establishing a new paradigm for efficient, high-fidelity MRI reconstruction.",
    "problem_framing": "We reframe accelerated MRI reconstruction from a static inverse optimization problem into a dynamic sequence generation task governed by Autoregressive Image Diffusion (AID). Traditional methods often view MRI recovery as a one-time mapping, ignoring the sequential dependencies inherent in high-dimensional data distributions. By transforming the reconstruction process into an autoregressive generative modeling problem, we can capture complex spatial correlations and uncertainties in the posterior distribution. However, this shift introduces the challenge of generating coherent image sequences efficiently, requiring a fundamental rethinking of how we approach sampling in the context of medical imaging physics.",
    "gap_pattern": "Current approaches for MRI reconstruction using generative models fail to effectively balance the computational demands of sequential sampling with the need for high diagnostic fidelity. Existing diffusion-based methods are limited by isotropic diffusion assumptions and require prohibitively slow sampling processes, involving hundreds to thousands of neural network evaluations. This inefficiency prevents their practical application in clinical settings where speed is paramount. Furthermore, these methods lack the specialized mechanisms to handle the autoregressive nature of image sequence generation, resulting in artifacts and inconsistencies when sampling from complex posteriors in accelerated MRI scenarios.",
    "solution": "We introduce the Autoregressive Image Diffusion (AID) model to address the dual challenges of posterior sampling fidelity and computational efficiency in MRI reconstruction. Our solution leverages the semilinear structure of diffusion processes to implement a Diffusion Exponential Integrator Sampler (DEIS), which serves as the engine for rapid image sequence generation. By reframing the sampling trajectory as a numerical integration problem, we employ exponential integrators to drastically reduce discretization errors with fewer steps. Additionally, we modify the score network parameterization to support deterministic sampling within the autoregressive framework, ensuring stability and consistency across the generated sequence. This architecture not only accelerates the reconstruction process but also enhances the quality of the sampled posterior by effectively utilizing the temporal dependencies inherent in the AID model.",
    "method_skeleton": "Construct the Autoregressive Image Diffusion (AID) architecture to model the conditional distribution of MRI image sequences given undersampled k-space data; Implement a Diffusion Exponential Integrator Sampler (DEIS) using exponential integrators to discretize the diffusion ODEs, minimizing error and accelerating the sampling process; Modify the score network parameterization to enable deterministic, high-fidelity posterior sampling across the autoregressive steps; Integrate quasi-Taylor schemes with ideal derivative substitution to further reduce neural function evaluations during the reconstruction phase.",
    "innovation_claims": [
      "Transform MRI reconstruction from static recovery to a dynamic autoregressive process by introducing Autoregressive Image Diffusion (AID), enabling the coherent modeling of image sequences and complex posterior distributions inherently present in accelerated MRI.",
      "Revolutionize the sampling efficiency of diffusion-based MRI reconstruction by integrating a Diffusion Exponential Integrator Sampler (DEIS), which reframes the slow sampling trajectory as a semilinear ODE problem solvable with exponential integrators, drastically reducing computational costs.",
      "Enhance the fidelity of posterior sampling by modifying the score network parameterization to support deterministic sampling, thereby transforming the stochastic autoregressive generation into a stable and reliable process suitable for clinical diagnostic requirements."
    ],
    "experiments_plan": "We evaluate the AID model on the fastMRI dataset, comparing reconstruction quality (PSNR, SSIM) and sampling time against standard diffusion models and compressed sensing baselines. Ablation studies will validate the contributions of the exponential integrator and the autoregressive structure."
  },
  "review_history": [
    {
      "pass": true,
      "avg_score": 6.669999999999901,
      "reviews": [
        {
          "reviewer": "Reviewer A",
          "role": "Methodology",
          "score": 6.369999999999908,
          "feedback": "Main gaps: Limited theoretical foundation compared to anchors with convergence bounds, Novelty mainly in combination rather than new mathematical concepts, Lack of clinical validation for medical imaging application. Anchored against 9 papers."
        },
        {
          "reviewer": "Reviewer B",
          "role": "Novelty",
          "score": 6.629999999999902,
          "feedback": "Main gaps: Limited theoretical justification for the autoregressive approach in MRI reconstruction, Lack of comparison with other state-of-the-art diffusion-based MRI reconstruction methods, Potential concerns about the clinical applicability and generalization of the proposed method. Anchored against 9 papers."
        },
        {
          "reviewer": "Reviewer C",
          "role": "Storyteller",
          "score": 7.009999999999894,
          "feedback": "Main gaps: Limited theoretical analysis compared to anchor papers with convergence bounds, Narrow application focus on MRI reconstruction limits broader applicability, Potential lack of novelty in combining autoregressive modeling with diffusion models and exponential integrators. Anchored against 9 papers."
        }
      ],
      "main_issue": "stability",
      "suggestions": [
        "从stability维度选择稳健Pattern",
        "注入成熟方法增强鲁棒性"
      ],
      "audit": {
        "pattern_id": "pattern_100",
        "anchors": [
          {
            "paper_id": "HyjIEf90Tn",
            "title": "Glauber Generative Model: Discrete Diffusion Models via Binary Classification",
            "pattern_id": "pattern_100",
            "score10": 5.9319999999999995,
            "review_count": 5,
            "dispersion10": 1.08,
            "weight": 0.8614228217442572
          },
          {
            "paper_id": "spDUv05cEq",
            "title": "Flow-based Variational Mutual Information: Fast and Flexible Approximations",
            "pattern_id": "pattern_100",
            "score10": 6.040000000000001,
            "review_count": 5,
            "dispersion10": 1.2600000000000002,
            "weight": 0.7928139244371923
          },
          {
            "paper_id": "RZHdb7FnqlY",
            "title": "Towards the Detection of Diffusion Model Deepfakes",
            "pattern_id": "pattern_100",
            "score10": 6.25,
            "review_count": 6,
            "dispersion10": 4.140000000000001,
            "weight": 0.37858174106134496
          },
          {
            "paper_id": "RaR3ETzyKp",
            "title": "Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance",
            "pattern_id": "pattern_100",
            "score10": 6.49,
            "review_count": 4,
            "dispersion10": 0.9000000000000008,
            "weight": 0.8470725854916313
          },
          {
            "paper_id": "zWy7dqOcel",
            "title": "Sampling with Mollified Interaction Energy Descent",
            "pattern_id": "pattern_100",
            "score10": 7.057,
            "review_count": 5,
            "dispersion10": 1.7099999999999995,
            "weight": 0.6611658558037105
          },
          {
            "paper_id": "r5njV3BsuD",
            "title": "Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization",
            "pattern_id": "pattern_100",
            "score10": 6.477142857142857,
            "review_count": 7,
            "dispersion10": 0.9000000000000008,
            "weight": 1.0944429166735974
          },
          {
            "paper_id": "PP1rudnxiW",
            "title": "Transport meets Variational Inference: Controlled Monte Carlo Diffusions",
            "pattern_id": "pattern_100",
            "score10": 6.430000000000001,
            "review_count": 6,
            "dispersion10": 0.9000000000000008,
            "weight": 1.0241632363449014
          },
          {
            "paper_id": "Y8KK9kjgIK",
            "title": "SigDiffusions: Score-Based Diffusion Models for Time Series via Log-Signature Embeddings",
            "pattern_id": "pattern_100",
            "score10": 5.589999999999999,
            "review_count": 4,
            "dispersion10": 2.5199999999999996,
            "weight": 0.45722667966877856
          },
          {
            "paper_id": "s7gnrEtWSm",
            "title": "Iterative $\\alpha$-(de)Blending: Learning a Deterministic Mapping Between Arbitrary Densities",
            "pattern_id": "pattern_100",
            "score10": 6.571,
            "review_count": 5,
            "dispersion10": 3.6900000000000004,
            "weight": 0.3820382663599264
          }
        ],
        "role_details": {
          "Methodology": {
            "comparisons": [
              {
                "paper_id": "HyjIEf90Tn",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID combines multiple techniques for MRI reconstruction, more complex than binary classification, score10: 5.9"
              },
              {
                "paper_id": "spDUv05cEq",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's specialized MRI approach is more impactful than flow-based mutual information, score10: 6.0"
              },
              {
                "paper_id": "RZHdb7FnqlY",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's technical complexity for medical imaging exceeds deepfake detection methodology, score10: 6.2"
              },
              {
                "paper_id": "RaR3ETzyKp",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "AID combines multiple techniques for specific application, more complex than rectified flow training, score10: 6.5"
              },
              {
                "paper_id": "zWy7dqOcel",
                "judgement": "worse",
                "confidence": 0.7,
                "rationale": "Mollified interaction energy descent offers more theoretical novelty than AID's application approach, score10: 7.1"
              },
              {
                "paper_id": "r5njV3BsuD",
                "judgement": "worse",
                "confidence": 0.7,
                "rationale": "Stochastic localization provides stronger theoretical foundation than AID's applied methodology, score10: 6.5"
              },
              {
                "paper_id": "PP1rudnxiW",
                "judgement": "worse",
                "confidence": 0.6,
                "rationale": "Controlled Monte Carlo diffusions offer more theoretical novelty than AID's application approach, score10: 6.4"
              },
              {
                "paper_id": "Y8KK9kjgIK",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's methodology for MRI reconstruction is more complex than log-signature embeddings, score10: 5.6"
              },
              {
                "paper_id": "s7gnrEtWSm",
                "judgement": "worse",
                "confidence": 0.6,
                "rationale": "Deterministic mapping between densities offers more theoretical novelty than AID's application approach, score10: 6.6"
              }
            ],
            "main_gaps": [
              "Limited theoretical foundation compared to anchors with convergence bounds",
              "Novelty mainly in combination rather than new mathematical concepts",
              "Lack of clinical validation for medical imaging application",
              "Unclear generalizability beyond MRI reconstruction"
            ],
            "score": 6.369999999999908,
            "loss": 0.35942072458262014,
            "avg_confidence": 0.6666666666666666,
            "monotonic_violations": 1
          },
          "Novelty": {
            "comparisons": [
              {
                "paper_id": "HyjIEf90Tn",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's novel autoregressive diffusion for MRI is more innovative than binary classification for discrete diffusion, score10: 5.9"
              },
              {
                "paper_id": "spDUv05cEq",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's autoregressive diffusion with exponential integrators is more novel than flow-based mutual information estimation, score10: 6.0"
              },
              {
                "paper_id": "RZHdb7FnqlY",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's autoregressive diffusion for MRI is more innovative than diffusion model deepfake detection, score10: 6.2"
              },
              {
                "paper_id": "RaR3ETzyKp",
                "judgement": "tie",
                "confidence": 0.6,
                "rationale": "AID's MRI reconstruction has similar novelty to improving rectified flow training via inter-path distance, score10: 6.5"
              },
              {
                "paper_id": "zWy7dqOcel",
                "judgement": "worse",
                "confidence": 0.7,
                "rationale": "AID's MRI reconstruction is less novel than sampling with mollified interaction energy descent, score10: 7.1"
              },
              {
                "paper_id": "r5njV3BsuD",
                "judgement": "tie",
                "confidence": 0.6,
                "rationale": "AID's MRI reconstruction has similar novelty to convergence bounds for diffusion via stochastic localization, score10: 6.5"
              },
              {
                "paper_id": "PP1rudnxiW",
                "judgement": "tie",
                "confidence": 0.6,
                "rationale": "AID's MRI reconstruction has similar novelty to combining transport methods with variational inference, score10: 6.4"
              },
              {
                "paper_id": "Y8KK9kjgIK",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's autoregressive diffusion for MRI is more novel than diffusion models for time series, score10: 5.6"
              },
              {
                "paper_id": "s7gnrEtWSm",
                "judgement": "tie",
                "confidence": 0.6,
                "rationale": "AID's MRI reconstruction has similar novelty to learning deterministic mappings between arbitrary densities, score10: 6.6"
              }
            ],
            "main_gaps": [
              "Limited theoretical justification for the autoregressive approach in MRI reconstruction",
              "Lack of comparison with other state-of-the-art diffusion-based MRI reconstruction methods",
              "Potential concerns about the clinical applicability and generalization of the proposed method"
            ],
            "score": 6.629999999999902,
            "loss": 0.07605419302636927,
            "avg_confidence": 0.6555555555555554,
            "monotonic_violations": 0
          },
          "Storyteller": {
            "comparisons": [
              {
                "paper_id": "HyjIEf90Tn",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's practical MRI application with efficient sampling is more impactful than theoretical binary classification, score10: 5.9"
              },
              {
                "paper_id": "spDUv05cEq",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's specific MRI application with efficiency improvements is more impactful than general mutual information approximation, score10: 6.0"
              },
              {
                "paper_id": "RZHdb7FnqlY",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's medical imaging application is more impactful than deepfake detection with similar technical complexity, score10: 6.2"
              },
              {
                "paper_id": "RaR3ETzyKp",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's specific MRI application with efficiency improvements is more impactful than general training improvements, score10: 6.5"
              },
              {
                "paper_id": "zWy7dqOcel",
                "judgement": "worse",
                "confidence": 0.6,
                "rationale": "Anchor's general sampling approach with higher score suggests broader impact than Story's specific MRI application, score10: 7.1"
              },
              {
                "paper_id": "r5njV3BsuD",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's practical MRI application with efficiency improvements is more impactful than theoretical convergence bounds, score10: 6.5"
              },
              {
                "paper_id": "PP1rudnxiW",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story's specific MRI application with efficiency improvements is more impactful than general transport and inference combination, score10: 6.4"
              },
              {
                "paper_id": "Y8KK9kjgIK",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "Story's efficiency improvements and medical application are more impactful than time series application with lower score, score10: 5.6"
              },
              {
                "paper_id": "s7gnrEtWSm",
                "judgement": "worse",
                "confidence": 0.6,
                "rationale": "Anchor's general deterministic mapping approach with higher score suggests broader impact than Story's specific MRI application, score10: 6.6"
              }
            ],
            "main_gaps": [
              "Limited theoretical analysis compared to anchor papers with convergence bounds",
              "Narrow application focus on MRI reconstruction limits broader applicability",
              "Potential lack of novelty in combining autoregressive modeling with diffusion models and exponential integrators"
            ],
            "score": 7.009999999999894,
            "loss": 0.14326958301616005,
            "avg_confidence": 0.6111111111111112,
            "monotonic_violations": 0
          }
        },
        "anchors_rounds": [
          [
            {
              "paper_id": "HyjIEf90Tn",
              "title": "Glauber Generative Model: Discrete Diffusion Models via Binary Classification",
              "pattern_id": "pattern_100",
              "score10": 5.9319999999999995,
              "review_count": 5,
              "dispersion10": 1.08,
              "weight": 0.8614228217442572
            },
            {
              "paper_id": "spDUv05cEq",
              "title": "Flow-based Variational Mutual Information: Fast and Flexible Approximations",
              "pattern_id": "pattern_100",
              "score10": 6.040000000000001,
              "review_count": 5,
              "dispersion10": 1.2600000000000002,
              "weight": 0.7928139244371923
            },
            {
              "paper_id": "RZHdb7FnqlY",
              "title": "Towards the Detection of Diffusion Model Deepfakes",
              "pattern_id": "pattern_100",
              "score10": 6.25,
              "review_count": 6,
              "dispersion10": 4.140000000000001,
              "weight": 0.37858174106134496
            },
            {
              "paper_id": "RaR3ETzyKp",
              "title": "Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance",
              "pattern_id": "pattern_100",
              "score10": 6.49,
              "review_count": 4,
              "dispersion10": 0.9000000000000008,
              "weight": 0.8470725854916313
            },
            {
              "paper_id": "zWy7dqOcel",
              "title": "Sampling with Mollified Interaction Energy Descent",
              "pattern_id": "pattern_100",
              "score10": 7.057,
              "review_count": 5,
              "dispersion10": 1.7099999999999995,
              "weight": 0.6611658558037105
            },
            {
              "paper_id": "r5njV3BsuD",
              "title": "Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization",
              "pattern_id": "pattern_100",
              "score10": 6.477142857142857,
              "review_count": 7,
              "dispersion10": 0.9000000000000008,
              "weight": 1.0944429166735974
            },
            {
              "paper_id": "PP1rudnxiW",
              "title": "Transport meets Variational Inference: Controlled Monte Carlo Diffusions",
              "pattern_id": "pattern_100",
              "score10": 6.430000000000001,
              "review_count": 6,
              "dispersion10": 0.9000000000000008,
              "weight": 1.0241632363449014
            }
          ],
          [
            {
              "paper_id": "Y8KK9kjgIK",
              "title": "SigDiffusions: Score-Based Diffusion Models for Time Series via Log-Signature Embeddings",
              "pattern_id": "pattern_100",
              "score10": 5.589999999999999,
              "review_count": 4,
              "dispersion10": 2.5199999999999996,
              "weight": 0.45722667966877856
            },
            {
              "paper_id": "s7gnrEtWSm",
              "title": "Iterative $\\alpha$-(de)Blending: Learning a Deterministic Mapping Between Arbitrary Densities",
              "pattern_id": "pattern_100",
              "score10": 6.571,
              "review_count": 5,
              "dispersion10": 3.6900000000000004,
              "weight": 0.3820382663599264
            }
          ]
        ],
        "pass": {
          "mode": "two_of_three_q75_and_avg_ge_q50",
          "used_distribution": "pattern",
          "pattern_paper_count": 148,
          "q50": 6.25,
          "q75": 6.49,
          "count_roles_ge_q75": 2,
          "roles_ge_q75": {
            "Methodology": false,
            "Novelty": true,
            "Storyteller": true
          },
          "avg_ge_q50": true,
          "avg_score": 6.669999999999901
        }
      }
    }
  ],
  "results_dir": "results/run_20260131_124028_1894_ca362b",
  "novelty_report": {
    "run_id": "run_20260131_124028_1894_ca362b",
    "created_at": "2026-01-31T12:51:18.824195+00:00",
    "user_idea": "Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction",
    "embedding_available": true,
    "embedding_model": "Qwen/Qwen3-Embedding-8B",
    "top_k": 100,
    "thresholds": {
      "high": 0.88,
      "medium": 0.82
    },
    "risk_level": "low",
    "max_similarity": 0.6557393074035645,
    "candidates": [
      {
        "paper_id": "Loek7hfb46P",
        "title": "Fast Sampling of Diffusion Models with Exponential Integrator",
        "pattern_id": "pattern_100",
        "domain": "Machine Learning",
        "text_hash": "0aea4f541f32674144e4aaef17ca7bc5015733dcf7eaf9f2ea8fd58b35e1f01e",
        "cosine": 0.6557393074035645,
        "keyword_overlap": 0.17857142857142858
      },
      {
        "paper_id": "qeXcMutEZY",
        "title": "Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models Trained on Corrupted Data",
        "pattern_id": "pattern_49",
        "domain": "Machine Learning",
        "text_hash": "ab12790514782e57f8a77bf37779ebe8d98b379c4505fda197af756c511123a3",
        "cosine": 0.6326676607131958,
        "keyword_overlap": 0.09688581314878893
      },
      {
        "paper_id": "6EUtjXAvmj",
        "title": "Variational Diffusion Posterior Sampling with Midpoint Guidance",
        "pattern_id": "pattern_49",
        "domain": "Machine Learning",
        "text_hash": "409fa7e25287199214dfcec3dc4f4c911e53b60c683e6b5ab1676806a614d8cd",
        "cosine": 0.6113014221191406,
        "keyword_overlap": 0.10104529616724739
      },
      {
        "paper_id": "tplXNcHZs1",
        "title": "Diffusion Posterior Sampling for Linear Inverse Problem Solving: A Filtering Perspective",
        "pattern_id": "pattern_49",
        "domain": "Machine Learning",
        "text_hash": "afa2520fd3c02d1a21b964699156cc80727c795ab6b8c79b04cb88a2ac089211",
        "cosine": 0.6079820394515991,
        "keyword_overlap": 0.10847457627118644
      },
      {
        "paper_id": "0vqjc50HfcC",
        "title": "DDM$^2$: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models",
        "pattern_id": "",
        "domain": "Medical Imaging",
        "text_hash": "a65b79d04b833964ab7e6478af757c015bcd9754ad463e87c32facf553b10b75",
        "cosine": 0.6067171096801758,
        "keyword_overlap": 0.099644128113879
      },
      {
        "paper_id": "1YO4EE3SPB",
        "title": "A Variational Perspective on Solving Inverse Problems with Diffusion Models",
        "pattern_id": "pattern_49",
        "domain": "Computer Vision",
        "text_hash": "c5ec3e720ee46fb12f0eae3be28ee6ceb4c79601da5823759e48b0644caa5448",
        "cosine": 0.6062808632850647,
        "keyword_overlap": 0.1099290780141844
      },
      {
        "paper_id": "yVeNBxwL5W",
        "title": "MaRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers",
        "pattern_id": "pattern_100",
        "domain": "Machine Learning",
        "text_hash": "b4b933e0e01cc1e1d70ad7b075bc6a338fbcaff2d01fcbff37425b103868a15d",
        "cosine": 0.6039837598800659,
        "keyword_overlap": 0.1288135593220339
      },
      {
        "paper_id": "wxPnuFp8fZ",
        "title": "Self-Supervised Diffusion MRI Denoising via Iterative and Stable Refinement",
        "pattern_id": "",
        "domain": "Medical Imaging",
        "text_hash": "6b7cde32d7f09a924e1fd95330fd1a5b94156e8f138a2a9955b31e1f71e747ef",
        "cosine": 0.5982657670974731,
        "keyword_overlap": 0.10273972602739725
      },
      {
        "paper_id": "wmmDvZGFK7",
        "title": "PFDiff: Training-Free Acceleration of Diffusion Models Combining Past and Future Scores",
        "pattern_id": "pattern_100",
        "domain": "Machine Learning",
        "text_hash": "c873412f84761714475556e74a7d55a9f22253f92d61246013d76129e2b74b48",
        "cosine": 0.5957354307174683,
        "keyword_overlap": 0.12413793103448276
      },
      {
        "paper_id": "rCGleSgNBK",
        "title": "Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions",
        "pattern_id": "pattern_100",
        "domain": "Machine Learning",
        "text_hash": "6f68c40c7510d4f147c06e945bf126a4565354133504dc7332decb1b7738f44d",
        "cosine": 0.5860313177108765,
        "keyword_overlap": 0.13402061855670103
      }
    ],
    "notes": [
      "index_reused"
    ],
    "report_path": "results/run_20260131_124028_1894_ca362b/novelty_report.json",
    "pivot_attempts": 0,
    "action": "pivot"
  },
  "recall_audit": {
    "final_top_k": [
      {
        "pattern_id": "pattern_100",
        "name": "Reframing Diffusion Sampling Efficiency",
        "final_score": 1.201746166059375,
        "path1_score": 1.041083574295044,
        "path2_score": 0.0,
        "path3_score": 0.16066259176433093,
        "cluster_size": 148
      },
      {
        "pattern_id": "pattern_115",
        "name": "Semantic Alignment for Compositional Generation",
        "final_score": 0.674303454139328,
        "path1_score": 0.25385723114013675,
        "path2_score": 0.020000000000000004,
        "path3_score": 0.4004462229991913,
        "cluster_size": 107
      },
      {
        "pattern_id": "pattern_102",
        "name": "Text to 3D generation robustness",
        "final_score": 0.4798963576522828,
        "path1_score": 0.2566413879394531,
        "path2_score": 0.020000000000000004,
        "path3_score": 0.2032549697128296,
        "cluster_size": 50
      },
      {
        "pattern_id": "pattern_49",
        "name": "Reframing Inverse Problems with Diffusion",
        "final_score": 0.39806022421312337,
        "path1_score": 0.25667169094085696,
        "path2_score": 0.0,
        "path3_score": 0.14138853327226644,
        "cluster_size": 15
      },
      {
        "pattern_id": "pattern_114",
        "name": "Reframing Video Generation Challenges",
        "final_score": 0.37045553854217533,
        "path1_score": 0.2752640962600708,
        "path2_score": 0.0,
        "path3_score": 0.09519144228210452,
        "cluster_size": 44
      },
      {
        "pattern_id": "pattern_57",
        "name": "Preference Alignment Through Distributional Modeling",
        "final_score": 0.27318592071533204,
        "path1_score": 0.27318592071533204,
        "path2_score": 0.0,
        "path3_score": 0.0,
        "cluster_size": 111
      },
      {
        "pattern_id": "pattern_94",
        "name": "Reframing Generation Through Multi-Feature Integration",
        "final_score": 0.2681644201278687,
        "path1_score": 0.2681644201278687,
        "path2_score": 0.0,
        "path3_score": 0.0,
        "cluster_size": 34
      },
      {
        "pattern_id": "pattern_68",
        "name": "Language Model Driven Planning Paradigms",
        "final_score": 0.2571013689041138,
        "path1_score": 0.2571013689041138,
        "path2_score": 0.0,
        "path3_score": 0.0,
        "cluster_size": 20
      },
      {
        "pattern_id": "pattern_7",
        "name": "Reframing Audio Understanding Through Multimodal and Probabilistic Learning",
        "final_score": 0.25541176795959475,
        "path1_score": 0.25541176795959475,
        "path2_score": 0.0,
        "path3_score": 0.0,
        "cluster_size": 41
      },
      {
        "pattern_id": "pattern_99",
        "name": "Frequency Aware Adaptive Restoration",
        "final_score": 0.15380655369186405,
        "path1_score": 0.0,
        "path2_score": 0.0,
        "path3_score": 0.15380655369186405,
        "cluster_size": 23
      }
    ],
    "path1": {
      "top_ideas": [
        {
          "idea_id": "idea_8082",
          "similarity": 0.6984537839889526,
          "snippet": "Utilize image diffusion models to address video inverse problems by treating the time dimension as a batch dimension and ensuring batch consistency.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_7839",
          "similarity": 0.6927803158760071,
          "snippet": "Combine diffusion synchronization and score distillation sampling to enable zero-shot image generation in arbitrary spaces with weak conditioning.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_5588",
          "similarity": 0.688160240650177,
          "snippet": "Integrate autoregressive models with diffusion transformers to enhance long video generation by leveraging spatial and temporal information.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_3845",
          "similarity": 0.6829648017883301,
          "snippet": "Reframe autoregressive sequence generation as an imitation learning problem to address compounding errors and improve sequence quality.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4171",
          "similarity": 0.6704110503196716,
          "snippet": "Leverage diffusion models for flexible and controlled human motion generation through novel composition methods.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4315",
          "similarity": 0.6689131259918213,
          "snippet": "Introduce a diffusion model that learns from a single motion sequence to synthesize diverse and realistic animations without additional training.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_6340",
          "similarity": 0.6650488376617432,
          "snippet": "Integrate text and drag signals for precise and ambiguity-free image editing using diffusion models.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_4133",
          "similarity": 0.659588634967804,
          "snippet": "Enhance diffusion model diversity by annealing the conditioning signal during sampling to balance diversity and quality.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_6252",
          "similarity": 0.6575317978858948,
          "snippet": "Improve diffusion model training efficiency and generation quality by aligning noisy input states with clean image representations from external encoders.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_5061",
          "similarity": 0.6564894318580627,
          "snippet": "Introduce block diffusion models that combine the strengths of autoregressive and diffusion models to enable flexible-length generation and improved inference efficiency.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_4542",
          "similarity": 0.6561887264251709,
          "snippet": "Extend diffusion models to pixel-level sketch generation with scale-adaptive guidance to balance recognizability and complexity.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_5696",
          "similarity": 0.6525541543960571,
          "snippet": "Transform discrete diffusion model learning into a binary classification task to improve performance in language and image generation.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_1665",
          "similarity": 0.647049605846405,
          "snippet": "Enhance text-to-image generation by integrating retrieval mechanisms to improve image fidelity for rare entities.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_7137",
          "similarity": 0.6427534222602844,
          "snippet": "Introduce discrete diffusion models to address the limitations of autoregressive models in complex reasoning and planning tasks.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4607",
          "similarity": 0.6416792273521423,
          "snippet": "Introduce a filtering-based approach to efficiently and accurately sample from the Bayesian posterior in diffusion models for linear inverse problems.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_7456",
          "similarity": 0.6416034698486328,
          "snippet": "Integrate video generation and novel view synthesis into a unified diffusion model for consistent dynamic 3D content creation.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4280",
          "similarity": 0.6385294198989868,
          "snippet": "Introduce an autoregressive diffusion model for direct raw waveform generation, enabling high-fidelity and temporally coherent speech synthesis.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_5733",
          "similarity": 0.6346430778503418,
          "snippet": "Introduce Condition Contrastive Alignment to unify language and visual modalities in autoregressive visual generation, eliminating the need for guided sampling.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_8069",
          "similarity": 0.6336281299591064,
          "snippet": "Introduce a unified model for scalable visual content generation across multiple modalities by leveraging a view-wise sampling algorithm and autoregressive generation.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_7957",
          "similarity": 0.633034348487854,
          "snippet": "Introduce a unified diffusion model that combines blurring and noise to leverage both high-frequency and low-frequency image structures for improved generative performance.",
          "pattern_count": 1
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_100",
          "score": 1.041083574295044
        },
        {
          "pattern_id": "pattern_114",
          "score": 0.2752640962600708
        },
        {
          "pattern_id": "pattern_57",
          "score": 0.27318592071533204
        },
        {
          "pattern_id": "pattern_94",
          "score": 0.2681644201278687
        },
        {
          "pattern_id": "pattern_68",
          "score": 0.2571013689041138
        },
        {
          "pattern_id": "pattern_49",
          "score": 0.25667169094085696
        },
        {
          "pattern_id": "pattern_102",
          "score": 0.2566413879394531
        },
        {
          "pattern_id": "pattern_7",
          "score": 0.25541176795959475
        },
        {
          "pattern_id": "pattern_115",
          "score": 0.25385723114013675
        }
      ]
    },
    "path2": {
      "top_domains": [
        {
          "domain_id": "domain_1",
          "name": "Computer Vision",
          "weight": 1.0,
          "paper_count": 1076
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_112",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_115",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_103",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_105",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_102",
          "score": 0.020000000000000004
        }
      ]
    },
    "path3": {
      "top_papers": [
        {
          "paper_id": "VM8batVBWvg",
          "similarity": 0.7434985041618347,
          "title": "Discrete Predictor-Corrector Diffusion Models for Image Synthesis",
          "quality": 0.7350000000000001,
          "review_count": 4
        },
        {
          "paper_id": "mRieQgMtNTQ",
          "similarity": 0.7500475645065308,
          "title": "Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model",
          "quality": 0.7160000000000001,
          "review_count": 5
        },
        {
          "paper_id": "OnD9zGAGT0k",
          "similarity": 0.7511141896247864,
          "title": "Diffusion Posterior Sampling for General Noisy Inverse Problems",
          "quality": 0.6860000000000002,
          "review_count": 5
        },
        {
          "paper_id": "o3yygm3lnzS",
          "similarity": 0.6451258659362793,
          "title": "PV3D: A 3D Generative Model for Portrait Video Generation",
          "quality": 0.7580000000000001,
          "review_count": 5
        },
        {
          "paper_id": "op-ceGueqc4",
          "similarity": 0.7312357425689697,
          "title": "Scaling Laws For Deep Learning Based Image Reconstruction",
          "quality": 0.6566666666666666,
          "review_count": 6
        },
        {
          "paper_id": "jQj-_rLVXsj",
          "similarity": 0.6854962706565857,
          "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
          "quality": 0.683,
          "review_count": 5
        },
        {
          "paper_id": "U2g8OGONA_V",
          "similarity": 0.6693718433380127,
          "title": "Multi-domain image generation and translation with identifiability guarantees",
          "quality": 0.6809999999999999,
          "review_count": 5
        },
        {
          "paper_id": "UaAD-Nu86WX",
          "similarity": 0.6322396993637085,
          "title": "DiGress: Discrete Denoising diffusion for graph generation",
          "quality": 0.7162499999999999,
          "review_count": 4
        },
        {
          "paper_id": "8JqINxA-2a",
          "similarity": 0.6645233631134033,
          "title": "Unified Discrete Diffusion for Simultaneous Vision-Language Generation",
          "quality": 0.6679999999999999,
          "review_count": 5
        },
        {
          "paper_id": "gzqrANCF4g",
          "similarity": 0.6851406693458557,
          "title": "Language Model Beats Diffusion - Tokenizer is key to visual generation",
          "quality": 0.635,
          "review_count": 4
        },
        {
          "paper_id": "kJUS5nD0vPB",
          "similarity": 0.5843643546104431,
          "title": "Out-of-Distribution Detection and Selective Generation for Conditional Language Models",
          "quality": 0.74125,
          "review_count": 4
        },
        {
          "paper_id": "1-MBdJssZ-S",
          "similarity": 0.6407157182693481,
          "title": "Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation",
          "quality": 0.666,
          "review_count": 5
        },
        {
          "paper_id": "8pusxkLEQO",
          "similarity": 0.737634539604187,
          "title": "ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation",
          "quality": 0.5680000000000001,
          "review_count": 5
        },
        {
          "paper_id": "hQwb-lbM6EL",
          "similarity": 0.5901069045066833,
          "title": "InCoder: A Generative Model for Code Infilling and Synthesis",
          "quality": 0.7060000000000001,
          "review_count": 5
        },
        {
          "paper_id": "bvpkw7UIRdU",
          "similarity": 0.5483822822570801,
          "title": "On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation",
          "quality": 0.756,
          "review_count": 5
        },
        {
          "paper_id": "H2Gxil855b",
          "similarity": 0.6724796295166016,
          "title": "Atlas Gaussians Diffusion for 3D Generation",
          "quality": 0.616,
          "review_count": 5
        },
        {
          "paper_id": "BWuBDdXVnH",
          "similarity": 0.7266196608543396,
          "title": "ControlAR: Controllable Image Generation with Autoregressive Models",
          "quality": 0.568,
          "review_count": 5
        },
        {
          "paper_id": "M2SsqpxGtc",
          "similarity": 0.6666411757469177,
          "title": "CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation",
          "quality": 0.616,
          "review_count": 5
        },
        {
          "paper_id": "OuV9ZrkQlc",
          "similarity": 0.6925970911979675,
          "title": "ImagenHub: Standardizing the evaluation of conditional image generation models",
          "quality": 0.5880000000000001,
          "review_count": 5
        },
        {
          "paper_id": "QE1LFzXQPL",
          "similarity": 0.7150833606719971,
          "title": "ImageFolder: Autoregressive Image Generation with Folded Tokens",
          "quality": 0.5680000000000001,
          "review_count": 5
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_115",
          "score": 0.4004462229991913
        },
        {
          "pattern_id": "pattern_102",
          "score": 0.2032549697128296
        },
        {
          "pattern_id": "pattern_100",
          "score": 0.16066259176433093
        },
        {
          "pattern_id": "pattern_99",
          "score": 0.15380655369186405
        },
        {
          "pattern_id": "pattern_49",
          "score": 0.14138853327226644
        },
        {
          "pattern_id": "pattern_24",
          "score": 0.1297391426577419
        },
        {
          "pattern_id": "pattern_96",
          "score": 0.12536808642883301
        },
        {
          "pattern_id": "pattern_101",
          "score": 0.11765221002187731
        },
        {
          "pattern_id": "pattern_114",
          "score": 0.09519144228210452
        }
      ]
    }
  },
  "review_summary": {
    "total_reviews": 1,
    "final_score": 6.669999999999901
  },
  "refinement_summary": {
    "total_refinements": 0,
    "issues_addressed": []
  },
  "verification_summary": {
    "collision_detected": false,
    "max_similarity": 0.6557393074035645
  }
}