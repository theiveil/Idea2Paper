"""
çŸ¥è¯†å›¾è°±æ„å»ºè„šæœ¬ V2 - ç²¾ç®€ç‰ˆï¼ˆå››ç±»èŠ‚ç‚¹ï¼‰
å°†è®ºæ–‡æŠ½å–ç»“æœå’ŒPatternèšç±»ç»“æœç»„è£…æˆç²¾ç®€çš„çŸ¥è¯†å›¾è°±

èŠ‚ç‚¹ç±»å‹ï¼š
  - Idea: æ ¸å¿ƒåˆ›æ–°ç‚¹
  - Pattern: å†™ä½œå¥—è·¯ï¼ˆæ¥è‡ª patterns_structured.jsonï¼‰
  - Domain: ç ”ç©¶é¢†åŸŸ
  - Paper: è®ºæ–‡ï¼ˆå« Skeleton, Trick, Review è¯¦ç»†ä¿¡æ¯ï¼‰

è¾“å…¥:
  - data/{conference}/*_paper_node.json: è®ºæ–‡æŠ½å–ç»“æœ
  - output/patterns_structured.json: Patternèšç±»ç»“æœ

è¾“å‡º:
  - output/nodes_idea.json: Idea èŠ‚ç‚¹
  - output/nodes_pattern.json: Pattern èŠ‚ç‚¹
  - output/nodes_domain.json: Domain èŠ‚ç‚¹
  - output/nodes_paper.json: Paper èŠ‚ç‚¹
  - output/knowledge_graph_stats.json: ç»Ÿè®¡ä¿¡æ¯
"""

import hashlib
import json
from collections import defaultdict
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, List

from tqdm import tqdm

# ===================== é…ç½® =====================

SCRIPT_DIR = Path(__file__).resolve().parent
SCRIPTS_DIR = SCRIPT_DIR.parent
PROJECT_ROOT = SCRIPTS_DIR.parent

# è¾“å…¥è·¯å¾„
DATA_DIR = PROJECT_ROOT / "data"
PATTERNS_FILE = PROJECT_ROOT / "output" / "patterns_structured.json"

# è¾“å‡ºè·¯å¾„
OUTPUT_DIR = PROJECT_ROOT / "output"
NODES_IDEA = OUTPUT_DIR / "nodes_idea.json"
NODES_PATTERN = OUTPUT_DIR / "nodes_pattern.json"
NODES_DOMAIN = OUTPUT_DIR / "nodes_domain.json"
NODES_PAPER = OUTPUT_DIR / "nodes_paper.json"
STATS_FILE = OUTPUT_DIR / "knowledge_graph_stats.json"

CONFERENCES = ["ACL_2017", "ARR_2022", "COLING_2020"]


# ===================== æ•°æ®ç±» =====================

@dataclass
class GraphStats:
    """å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
    total_nodes: int = 0
    ideas: int = 0
    patterns: int = 0
    domains: int = 0
    papers: int = 0


# ===================== èŠ‚ç‚¹æ„å»ºå™¨ =====================

class KnowledgeGraphBuilderV2:
    """çŸ¥è¯†å›¾è°±æ„å»ºå™¨ V2 - å››ç±»èŠ‚ç‚¹ç‰ˆæœ¬"""

    def __init__(self):
        self.stats = GraphStats()

        # èŠ‚ç‚¹å­˜å‚¨
        self.idea_nodes: List[Dict] = []
        self.pattern_nodes: List[Dict] = []
        self.domain_nodes: List[Dict] = []
        self.paper_nodes: List[Dict] = []

        # å»é‡æ˜ å°„
        self.idea_map: Dict[str, str] = {}      # idea_hash -> idea_id
        self.domain_map: Dict[str, str] = {}    # domain_name -> domain_id
        self.pattern_map: Dict[int, str] = {}   # pattern_id -> pattern_id
        self.paper_map: Dict[str, str] = {}     # paper_id -> paper_id

    def build(self):
        """æ„å»ºå®Œæ•´çš„çŸ¥è¯†å›¾è°±"""
        print("=" * 60)
        print("ğŸš€ å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°± V2 (å››ç±»èŠ‚ç‚¹)")
        print("=" * 60)

        # Step 1: åŠ è½½æ•°æ®
        print("\nã€Step 1ã€‘åŠ è½½æ•°æ®")
        papers = self._load_papers()
        patterns = self._load_patterns()
        reviews = self._load_reviews()
        paper_to_pattern = self._load_paper_to_pattern()
        print(f"âœ… åŠ è½½ {len(papers)} ç¯‡è®ºæ–‡, {len(patterns)} ä¸ª Pattern, {len(reviews)} æ¡ Review")
        print(f"âœ… Paperâ†’Pattern æ˜ å°„: {len(paper_to_pattern)} ç¯‡è®ºæ–‡æœ‰ Pattern")

        # Step 2: æ„å»ºèŠ‚ç‚¹
        print("\nã€Step 2ã€‘æ„å»ºèŠ‚ç‚¹")
        self._build_idea_nodes(papers)
        self._build_pattern_nodes(patterns)
        self._build_domain_nodes(papers)
        self._build_paper_nodes(papers, reviews, paper_to_pattern)

        # Step 2.5: å¡«å…… Idea -> Pattern æ˜ å°„
        self._link_idea_pattern()

        # Step 3: ä¿å­˜èŠ‚ç‚¹
        print("\nã€Step 3ã€‘ä¿å­˜èŠ‚ç‚¹")
        self._save_nodes()

        # Step 4: ç»Ÿè®¡
        print("\nã€Step 4ã€‘ç»Ÿè®¡ä¿¡æ¯")
        self._update_stats()
        self._save_stats()
        self._print_stats()

        print("\n" + "=" * 60)
        print("âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ!")
        print("=" * 60)

    # ===================== æ•°æ®åŠ è½½ =====================

    def _load_papers(self) -> List[Dict]:
        """åŠ è½½æ‰€æœ‰è®ºæ–‡æ•°æ®"""
        papers = []
        for conference in CONFERENCES:
            conf_dir = DATA_DIR / conference
            if not conf_dir.exists():
                continue

            all_papers_file = conf_dir / "_all_paper_nodes.json"
            if all_papers_file.exists():
                with open(all_papers_file, 'r', encoding='utf-8') as f:
                    conf_papers = json.load(f)
                    papers.extend(conf_papers)
                    print(f"  ğŸ“‚ {conference}: {len(conf_papers)} ç¯‡")
            else:
                count = 0
                for file in conf_dir.glob("*_paper_node.json"):
                    if file.name.startswith("_"):
                        continue
                    with open(file, 'r', encoding='utf-8') as f:
                        papers.append(json.load(f))
                        count += 1
                if count > 0:
                    print(f"  ğŸ“‚ {conference}: {count} ç¯‡")
        return papers

    def _load_patterns(self) -> List[Dict]:
        """åŠ è½½ Pattern æ•°æ®"""
        if not PATTERNS_FILE.exists():
            print(f"âš ï¸  Pattern æ–‡ä»¶ä¸å­˜åœ¨: {PATTERNS_FILE}")
            return []
        with open(PATTERNS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _load_reviews(self) -> List[Dict]:
        """åŠ è½½æ‰€æœ‰ Review æ•°æ®"""
        reviews = []
        for conference in CONFERENCES:
            conf_dir = DATA_DIR / conference
            if not conf_dir.exists():
                continue

            all_reviews_file = conf_dir / "_all_review_nodes.json"
            if all_reviews_file.exists():
                with open(all_reviews_file, 'r', encoding='utf-8') as f:
                    conf_reviews = json.load(f)
                    reviews.extend(conf_reviews)
        return reviews

    def _load_paper_to_pattern(self) -> Dict[str, int]:
        """åŠ è½½ Paper â†’ Pattern æ˜ å°„"""
        mapping_file = OUTPUT_DIR / 'paper_to_pattern.json'
        if not mapping_file.exists():
            print(f"âš ï¸  paper_to_pattern.json ä¸å­˜åœ¨ï¼ŒPaper èŠ‚ç‚¹å°†æ—  pattern_ids")
            return {}
        with open(mapping_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    # ===================== æ„å»ºèŠ‚ç‚¹ =====================

    def _build_idea_nodes(self, papers: List[Dict]):
        """æ„å»º Idea èŠ‚ç‚¹ï¼ˆç¬¬ä¸€éï¼šä»…æ”¶é›† Idea å’Œ Paper æ˜ å°„ï¼‰"""
        print("\nğŸ’¡ æ„å»º Idea èŠ‚ç‚¹...")

        for paper in tqdm(papers, desc="Processing papers"):
            ideal_info = paper.get('ideal', {})
            core_idea = ideal_info.get('core_idea', '')

            if not core_idea:
                continue

            # ç”¨ hash å»é‡
            idea_hash = hashlib.md5(core_idea.encode()).hexdigest()[:16]

            if idea_hash not in self.idea_map:
                idea_id = f"idea_{len(self.idea_nodes)}"
                self.idea_map[idea_hash] = idea_id

                self.idea_nodes.append({
                    'idea_id': idea_id,
                    'description': core_idea,
                    'tech_stack': ideal_info.get('tech_stack', []),
                    'input_type': ideal_info.get('input_type', ''),
                    'output_type': ideal_info.get('output_type', ''),
                    'source_paper_ids': [paper.get('paper_id', '')],  # è®°å½•æ¥æº
                    'pattern_ids': []  # å ä½ï¼Œç¨åå¡«å……
                })
            else:
                # å·²å­˜åœ¨çš„ Ideaï¼Œè¿½åŠ  paper_id
                idea_id = self.idea_map[idea_hash]
                for idea_node in self.idea_nodes:
                    if idea_node['idea_id'] == idea_id:
                        if paper.get('paper_id', '') not in idea_node['source_paper_ids']:
                            idea_node['source_paper_ids'].append(paper.get('paper_id', ''))
                        break

        print(f"  âœ“ åˆ›å»º {len(self.idea_nodes)} ä¸ª Idea èŠ‚ç‚¹")

    def _build_pattern_nodes(self, patterns: List[Dict]):
        """æ„å»º Pattern èŠ‚ç‚¹ï¼ˆç›´æ¥ä½¿ç”¨ patterns_structured.jsonï¼‰"""
        print("\nğŸ“‹ æ„å»º Pattern èŠ‚ç‚¹...")

        for pattern in patterns:
            pattern_id = pattern.get('pattern_id')
            self.pattern_map[pattern_id] = f"pattern_{pattern_id}"

            # æå–å…³é”®ä¿¡æ¯
            self.pattern_nodes.append({
                'pattern_id': f"pattern_{pattern_id}",
                'name': pattern.get('pattern_name', ''),
                'summary': pattern.get('pattern_summary', ''),
                'writing_guide': pattern.get('writing_guide', ''),
                'cluster_size': pattern.get('metadata', {}).get('cluster_size', 0),
                'coherence_score': pattern.get('metadata', {}).get('coherence_score', 0),
                'paper_ids': pattern.get('metadata', {}).get('all_paper_ids', []),

                # ç²¾ç®€çš„ Skeleton å’Œ Trick ç»Ÿè®¡
                'skeleton_count': len(pattern.get('skeleton_examples', [])),
                'trick_count': len(pattern.get('common_tricks', [])),
                'top_tricks': [
                    {
                        'name': t.get('trick_name', ''),
                        'frequency': t.get('frequency', 0),
                        'percentage': t.get('percentage', '')
                    }
                    for t in pattern.get('common_tricks', [])[:5]  # ä»…ä¿ç•™ Top 5
                ]
            })

        print(f"  âœ“ åˆ›å»º {len(self.pattern_nodes)} ä¸ª Pattern èŠ‚ç‚¹")

    def _build_domain_nodes(self, papers: List[Dict]):
        """æ„å»º Domain èŠ‚ç‚¹"""
        print("\nğŸŒ æ„å»º Domain èŠ‚ç‚¹...")

        domain_stats = defaultdict(lambda: {
            'paper_count': 0,
            'research_objects': set(),
            'core_techniques': set(),
            'applications': set()
        })

        for paper in tqdm(papers, desc="Processing papers"):
            domain_info = paper.get('domain', {})
            domains_list = domain_info.get('domains', [])

            for domain_name in domains_list:
                if not domain_name:
                    continue

                domain_stats[domain_name]['paper_count'] += 1

                # èšåˆä¿¡æ¯
                if domain_info.get('research_object'):
                    domain_stats[domain_name]['research_objects'].add(
                        domain_info['research_object']
                    )
                if domain_info.get('core_technique'):
                    domain_stats[domain_name]['core_techniques'].add(
                        domain_info['core_technique']
                    )
                if domain_info.get('application'):
                    domain_stats[domain_name]['applications'].add(
                        domain_info['application']
                    )

        # ç”Ÿæˆ Domain èŠ‚ç‚¹
        for domain_name, stats in domain_stats.items():
            domain_id = f"domain_{len(self.domain_nodes)}"
            self.domain_map[domain_name] = domain_id

            self.domain_nodes.append({
                'domain_id': domain_id,
                'name': domain_name,
                'paper_count': stats['paper_count'],
                'research_objects': list(stats['research_objects']),
                'core_techniques': list(stats['core_techniques']),
                'applications': list(stats['applications'])
            })

        print(f"  âœ“ åˆ›å»º {len(self.domain_nodes)} ä¸ª Domain èŠ‚ç‚¹")

    def _build_paper_nodes(self, papers: List[Dict], reviews: List[Dict], paper_to_pattern: Dict[str, int]):
        """æ„å»º Paper èŠ‚ç‚¹ï¼ˆåµŒå…¥ Skeleton, Trick, Reviewï¼‰"""
        print("\nğŸ“„ æ„å»º Paper èŠ‚ç‚¹...")

        # æ„å»º review æ˜ å°„
        review_map = defaultdict(list)
        for review in reviews:
            paper_id = review.get('paper_id', '')
            if paper_id:
                review_map[paper_id].append({
                    'reviewer': review.get('reviewer', ''),
                    'overall_score': review.get('overall_score', ''),
                    'confidence': review.get('confidence', ''),
                    'summary': review.get('paper_summary', '')[:300],
                    'strengths': review.get('strengths', '')[:300],
                    'weaknesses': review.get('weaknesses', '')[:300]
                })

        for paper in tqdm(papers, desc="Processing papers"):
            paper_id = paper.get('paper_id', '')
            self.paper_map[paper_id] = paper_id

            # æå–åŸºç¡€ä¿¡æ¯
            ideal_info = paper.get('ideal', {})
            domain_info = paper.get('domain', {})
            skeleton = paper.get('skeleton', {})
            tricks = paper.get('tricks', [])

            # æ„å»º Paper èŠ‚ç‚¹
            self.paper_nodes.append({
                'paper_id': paper_id,
                'title': paper.get('title', ''),
                'conference': paper.get('conference', ''),

                # Idea ä¿¡æ¯
                'idea': {
                    'core_idea': ideal_info.get('core_idea', ''),
                    'tech_stack': ideal_info.get('tech_stack', []),
                    'input_type': ideal_info.get('input_type', ''),
                    'output_type': ideal_info.get('output_type', '')
                },

                # Domain ä¿¡æ¯
                'domains': domain_info.get('domains', []),

                # Skeleton ä¿¡æ¯ï¼ˆå®Œæ•´ä¿ç•™ï¼‰
                'skeleton': {
                    'problem_framing': skeleton.get('problem_framing', ''),
                    'gap_pattern': skeleton.get('gap_pattern', ''),
                    'method_story': skeleton.get('method_story', ''),
                    'experiments_story': skeleton.get('experiments_story', '')
                },

                # Tricks ä¿¡æ¯ï¼ˆå®Œæ•´ä¿ç•™ï¼‰
                'tricks': [
                    {
                        'name': t.get('name', ''),
                        'type': t.get('type', ''),
                        'description': t.get('description', ''),
                        'purpose': t.get('purpose', ''),
                        'location': t.get('location', '')
                    }
                    for t in tricks
                ],

                # Review ä¿¡æ¯
                'reviews': review_map.get(paper_id, []),

                # Pattern å½’å±ï¼ˆä» paper_to_pattern æ˜ å°„è·å–ï¼‰
                'pattern_ids': [f"pattern_{paper_to_pattern[paper_id]}"] if paper_id in paper_to_pattern else []
            })

        print(f"  âœ“ åˆ›å»º {len(self.paper_nodes)} ä¸ª Paper èŠ‚ç‚¹")

    def _link_idea_pattern(self):
        """å¡«å…… Idea èŠ‚ç‚¹çš„ pattern_idsï¼ˆé€šè¿‡ Paper ä¸­è½¬ï¼‰"""
        print("\nğŸ”— æ„å»º Idea -> Pattern æ˜ å°„...")

        # éå†æ¯ä¸ª Idea
        for idea_node in self.idea_nodes:
            idea_id = idea_node['idea_id']
            pattern_ids_set = set()

            # æ‰¾åˆ°æ‰€æœ‰å®ç°è¯¥ Idea çš„ Paper
            for paper_id in idea_node['source_paper_ids']:
                # ä» Paper ä¸­è·å– pattern_ids
                for paper_node in self.paper_nodes:
                    if paper_node['paper_id'] == paper_id:
                        pattern_ids_set.update(paper_node['pattern_ids'])
                        break

            # å¡«å……åˆ° Idea èŠ‚ç‚¹
            idea_node['pattern_ids'] = sorted(list(pattern_ids_set))

        total_connections = sum(len(idea['pattern_ids']) for idea in self.idea_nodes)
        print(f"  âœ“ å…±å»ºç«‹ {total_connections} ä¸ª Idea->Pattern è¿æ¥")
        print(f"  âœ“ å¹³å‡æ¯ä¸ª Idea è¿æ¥ {total_connections/len(self.idea_nodes):.1f} ä¸ª Pattern")

    # ===================== ä¿å­˜å’Œç»Ÿè®¡ =====================

    def _save_nodes(self):
        """ä¿å­˜æ‰€æœ‰èŠ‚ç‚¹åˆ°ç‹¬ç«‹æ–‡ä»¶"""
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜ Idea èŠ‚ç‚¹
        with open(NODES_IDEA, 'w', encoding='utf-8') as f:
            json.dump(self.idea_nodes, f, ensure_ascii=False, indent=2)
        print(f"  âœ“ {NODES_IDEA}")

        # ä¿å­˜ Pattern èŠ‚ç‚¹
        with open(NODES_PATTERN, 'w', encoding='utf-8') as f:
            json.dump(self.pattern_nodes, f, ensure_ascii=False, indent=2)
        print(f"  âœ“ {NODES_PATTERN}")

        # ä¿å­˜ Domain èŠ‚ç‚¹
        with open(NODES_DOMAIN, 'w', encoding='utf-8') as f:
            json.dump(self.domain_nodes, f, ensure_ascii=False, indent=2)
        print(f"  âœ“ {NODES_DOMAIN}")

        # ä¿å­˜ Paper èŠ‚ç‚¹
        with open(NODES_PAPER, 'w', encoding='utf-8') as f:
            json.dump(self.paper_nodes, f, ensure_ascii=False, indent=2)
        print(f"  âœ“ {NODES_PAPER}")

    def _update_stats(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats.ideas = len(self.idea_nodes)
        self.stats.patterns = len(self.pattern_nodes)
        self.stats.domains = len(self.domain_nodes)
        self.stats.papers = len(self.paper_nodes)
        self.stats.total_nodes = (
            self.stats.ideas +
            self.stats.patterns +
            self.stats.domains +
            self.stats.papers
        )

    def _save_stats(self):
        """ä¿å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with open(STATS_FILE, 'w', encoding='utf-8') as f:
            json.dump(asdict(self.stats), f, ensure_ascii=False, indent=2)
        print(f"  âœ“ {STATS_FILE}")

    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š çŸ¥è¯†å›¾è°±ç»Ÿè®¡ (V2):")
        print("-" * 40)
        print(f"  æ€»èŠ‚ç‚¹æ•°:  {self.stats.total_nodes}")
        print(f"  Idea:      {self.stats.ideas}")
        print(f"  Pattern:   {self.stats.patterns}")
        print(f"  Domain:    {self.stats.domains}")
        print(f"  Paper:     {self.stats.papers}")
        print("-" * 40)


def main():
    """ä¸»å‡½æ•°"""
    builder = KnowledgeGraphBuilderV2()
    builder.build()


if __name__ == '__main__':
    main()
